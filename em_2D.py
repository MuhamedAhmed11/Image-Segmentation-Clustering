# Reference: https://colab.research.google.com/drive/1Eb-G95_dd3XJ-0hm2qDqdtqMugLkSYE8?ref=morioh.com&utm_source=morioh.com#scrollTo=erwQND925xoe

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import multivariate_normal
from sklearn.datasets import make_spd_matrix
from sklearn.mixture import GaussianMixture
from plot_gmm import plot_gmm
import time
# To calcualte the execution time (Speed of the Algorithm)
start_time = time.time()

plt.rcParams["axes.grid"] = False

# define the number of samples to be drawn
n_samples = 100

# define the mean points for each of the synthetic cluster centers
t_means = [[8.4, 8.2], [1.4, 1.6], [2.4, 5.4], [6.4, 2.4]]

# for each cluster center, create a Positive semi-definite covariance matrix
t_covs = []
for s in range(len(t_means)):
    t_covs.append(make_spd_matrix(2))

# X = []
# for mean, cov in zip(t_means, t_covs):
#     x = np.random.multivariate_normal(mean, cov, n_samples)
#     X += list(x)
# X = np.array(X)
# np.random.shuffle(X)
# print(X)
# print("Dataset shape:", X.shape)
# np.save('x_array', X)

X = np.load('x_array.npy')

# Create a grid for visualization purposes
x = np.linspace(np.min(X[..., 0]) - 1, np.max(X[..., 0]) + 1, 100)
y = np.linspace(np.min(X[..., 1]) - 1, np.max(X[..., 1]) + 1, 80)
X_, Y_ = np.meshgrid(x, y)
pos = np.array([X_.flatten(), Y_.flatten()]).T
# print(pos.shape)
# print(np.max(pos[..., 1]))

# gmm = GaussianMixture(n_components=4, random_state=42)
# plot_gmm(gmm, X)
# plt.show()



# define the number of clusters to be learned
k = 4

# create and initialize the cluster centers and the weight parameters
weights = np.ones(k) / k
means = np.random.choice(X.flatten(), (k, X.shape[1]))
print(means)
print(weights)

# create and initialize a Positive semi-definite covariance matrix
cov = []
for i in range(k):
    cov.append(make_spd_matrix(X.shape[1]))
cov = np.array(cov)
print(cov.shape)

colors = ['tab:blue', 'tab:orange', 'tab:green', 'magenta', 'yellow', 'red', 'brown', 'grey']
eps = 1e-8

# run GMM for 40 steps
for step in range(40):

    # visualize the learned clusters
    if step % 1 == 0:
        # plt.figure(figsize=(12, int(8)))
        # plt.title("Iteration {}".format(step))
        # axes = plt.gca()

        likelihood = []
        for j in range(k):
            likelihood.append(multivariate_normal.pdf(x=pos, mean=means[j], cov=cov[j]))
        likelihood = np.array(likelihood)
        predictions = np.argmax(likelihood, axis=0)

        for c in range(k):
            pred_ids = np.where(predictions == c)
            # plt.scatter(pos[pred_ids[0], 0], pos[pred_ids[0], 1], color=colors[c], alpha=0.2, edgecolors='none',
            #             marker='s')

        # plt.scatter(X[..., 0], X[..., 1], facecolors='none', edgecolors='grey')

        # for j in range(k):
        #     plt.scatter(means[j][0], means[j][1], color=colors[j], marker='X', s=100)

        # plt.savefig("img_{0:02d}".format(step), bbox_inches='tight')
        # plt.show()

    likelihood = []
    # Expectation step
    for j in range(k):
        likelihood.append(multivariate_normal.pdf(x=X, mean=means[j], cov=cov[j]))
    likelihood = np.array(likelihood)
    assert likelihood.shape == (k, len(X))

    b = []
    # Maximization step
    for j in range(k):
        # use the current values for the parameters to evaluate the posterior
        # probabilities of the data to have been generated by each gaussian
        b.append((likelihood[j] * weights[j]) / (np.sum([likelihood[i] * weights[i] for i in range(k)], axis=0) + eps))

        # update mean and variance
        means[j] = np.sum(b[j].reshape(len(X), 1) * X, axis=0) / (np.sum(b[j] + eps))
        cov[j] = np.dot((b[j].reshape(len(X), 1) * (X - means[j])).T, (X - means[j])) / (np.sum(b[j]) + eps)

        # update the weights
        weights[j] = np.mean(b[j])

        assert cov.shape == (k, X.shape[1], X.shape[1])
        assert means.shape == (k, X.shape[1])

# To calcualte the execution time (Speed of the Algorithm)
end_time = time.time()
total_time = end_time - start_time
print("Runtime: %s seconds " % (total_time))